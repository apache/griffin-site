I"¦E<h2 id="apache-griffin-å…¥é—¨æŒ‡å—">Apache Griffin å…¥é—¨æŒ‡å—</h2>

<p>æ•°æ®è´¨é‡æ¨¡å—æ˜¯å¤§æ•°æ®å¹³å°ä¸­å¿…ä¸å¯å°‘çš„ä¸€ä¸ªåŠŸèƒ½ç»„ä»¶ï¼Œ<a href="http://griffin.apache.org">Apache Griffin</a>ï¼ˆä»¥ä¸‹ç®€ç§°Griffinï¼‰æ˜¯ä¸€ä¸ªå¼€æºçš„å¤§æ•°æ®æ•°æ®è´¨é‡è§£å†³æ–¹æ¡ˆï¼Œå®ƒæ”¯æŒæ‰¹å¤„ç†å’Œæµæ¨¡å¼ä¸¤ç§æ•°æ®è´¨é‡æ£€æµ‹æ–¹å¼ï¼Œå¯ä»¥ä»ä¸åŒç»´åº¦ï¼ˆæ¯”å¦‚ç¦»çº¿ä»»åŠ¡æ‰§è¡Œå®Œæ¯•åæ£€æŸ¥æºç«¯å’Œç›®æ ‡ç«¯çš„æ•°æ®æ•°é‡æ˜¯å¦ä¸€è‡´ã€æºè¡¨çš„æ•°æ®ç©ºå€¼æ•°é‡ç­‰ï¼‰åº¦é‡æ•°æ®èµ„äº§ï¼Œä»è€Œæå‡æ•°æ®çš„å‡†ç¡®åº¦ã€å¯ä¿¡åº¦ã€‚</p>

<p>åœ¨Griffinçš„æ¶æ„ä¸­ï¼Œä¸»è¦åˆ†ä¸ºDefineã€Measureå’ŒAnalyzeä¸‰ä¸ªéƒ¨åˆ†ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š</p>

<p><img src="/images/arch-1.png" alt="arch" /></p>

<p>å„éƒ¨åˆ†çš„èŒè´£å¦‚ä¸‹ï¼š</p>

<ul>
  <li>Defineï¼šä¸»è¦è´Ÿè´£å®šä¹‰æ•°æ®è´¨é‡ç»Ÿè®¡çš„ç»´åº¦ï¼Œæ¯”å¦‚æ•°æ®è´¨é‡ç»Ÿè®¡çš„æ—¶é—´è·¨åº¦ã€ç»Ÿè®¡çš„ç›®æ ‡ï¼ˆæºç«¯å’Œç›®æ ‡ç«¯çš„æ•°æ®æ•°é‡æ˜¯å¦ä¸€è‡´ï¼Œæ•°æ®æºé‡ŒæŸä¸€å­—æ®µçš„éç©ºçš„æ•°é‡ã€ä¸é‡å¤å€¼çš„æ•°é‡ã€æœ€å¤§å€¼ã€æœ€å°å€¼ã€top5çš„å€¼æ•°é‡ç­‰ï¼‰</li>
  <li>Measureï¼šä¸»è¦è´Ÿè´£æ‰§è¡Œç»Ÿè®¡ä»»åŠ¡ï¼Œç”Ÿæˆç»Ÿè®¡ç»“æœ</li>
  <li>Analyzeï¼šä¸»è¦è´Ÿè´£ä¿å­˜ä¸å±•ç¤ºç»Ÿè®¡ç»“æœ</li>
</ul>

<p>åŸºäºä»¥ä¸ŠåŠŸèƒ½ï¼Œæˆ‘ä»¬å¤§æ•°æ®å¹³å°è®¡åˆ’å¼•å…¥Griffinä½œä¸ºæ•°æ®è´¨é‡è§£å†³æ–¹æ¡ˆï¼Œå®ç°æ•°æ®ä¸€è‡´æ€§æ£€æŸ¥ã€ç©ºå€¼ç»Ÿè®¡ç­‰åŠŸèƒ½ã€‚ä»¥ä¸‹æ˜¯å®‰è£…æ­¥éª¤æ€»ç»“ï¼š</p>

<h3 id="å®‰è£…éƒ¨ç½²">å®‰è£…éƒ¨ç½²</h3>

<h4 id="ä¾èµ–å‡†å¤‡">ä¾èµ–å‡†å¤‡</h4>

<ul>
  <li>JDK (1.8 or later versions)</li>
  <li>MySQL(version 5.6åŠä»¥ä¸Š)</li>
  <li>Hadoop (2.6.0 or later)</li>
  <li>Hive (version 2.x)</li>
  <li>Spark (version 2.2.1)</li>
  <li>Livyï¼ˆlivy-0.5.0-incubatingï¼‰</li>
  <li>ElasticSearch (5.0 or later versions)</li>
</ul>

<h4 id="åˆå§‹åŒ–">åˆå§‹åŒ–</h4>

<p>åˆå§‹åŒ–æ“ä½œå…·ä½“è¯·å‚è€ƒ<a href="https://github.com/apache/griffin/blob/master/griffin-doc/deploy/deploy-guide.md">Apache Griffin Deployment Guide</a>ï¼Œç”±äºæˆ‘çš„æµ‹è¯•ç¯å¢ƒä¸­Hadoopé›†ç¾¤ã€Hiveé›†ç¾¤å·²æ­å¥½ï¼Œæ•…è¿™é‡Œçœç•¥Hadoopã€Hiveå®‰è£…æ­¥éª¤ï¼Œåªä¿ç•™æ‹·è´é…ç½®æ–‡ä»¶ã€é…ç½®Hadoopé…ç½®æ–‡ä»¶ç›®å½•æ­¥éª¤ã€‚</p>

<p>1ã€MySQLï¼š</p>

<p>åœ¨MySQLä¸­åˆ›å»ºæ•°æ®åº“quartzï¼Œç„¶åæ‰§è¡Œ<a href="https://github.com/apache/griffin/blob/master/service/src/main/resources/Init_quartz_mysql_innodb.sql">Init_quartz_mysql_innodb.sql</a>è„šæœ¬åˆå§‹åŒ–è¡¨ä¿¡æ¯ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mysql -u &lt;username&gt; -p &lt;password&gt; &lt; Init_quartz_mysql_innodb.sql
</code></pre></div></div>

<p>2ã€Hadoopå’ŒHiveï¼š</p>

<p>ä»HadoopæœåŠ¡å™¨æ‹·è´é…ç½®æ–‡ä»¶åˆ°LivyæœåŠ¡å™¨ä¸Šï¼Œè¿™é‡Œå‡è®¾å°†é…ç½®æ–‡ä»¶æ”¾åœ¨/usr/data/confç›®å½•ä¸‹ã€‚</p>

<p>åœ¨HadoopæœåŠ¡å™¨ä¸Šåˆ›å»º/home/spark_confç›®å½•ï¼Œå¹¶å°†Hiveçš„é…ç½®æ–‡ä»¶hive-site.xmlä¸Šä¼ åˆ°è¯¥ç›®å½•ä¸‹ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#åˆ›å»º/home/spark_confç›®å½•
hadoop fs -mkdir -p /home/spark_conf
#ä¸Šä¼ hive-site.xml
hadoop fs -put hive-site.xml /home/spark_conf/
</code></pre></div></div>

<p>3ã€è®¾ç½®ç¯å¢ƒå˜é‡ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/bin/bash
export JAVA_HOME=/data/jdk1.8.0_192

#sparkç›®å½•
export SPARK_HOME=/usr/data/spark-2.1.1-bin-2.6.3
#livyå‘½ä»¤ç›®å½•
export LIVY_HOME=/usr/data/livy/bin
#hadoopé…ç½®æ–‡ä»¶ç›®å½•
export HADOOP_CONF_DIR=/usr/data/conf
</code></pre></div></div>

<p>4ã€Livyé…ç½®ï¼š</p>

<p>æ›´æ–°livy/confä¸‹çš„livy.confé…ç½®æ–‡ä»¶ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>livy.server.host = 127.0.0.1
livy.spark.master = yarn
livy.spark.deployMode = cluster
livy.repl.enable-hive-context = true
</code></pre></div></div>

<p>å¯åŠ¨livyï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>livy-server start
</code></pre></div></div>

<p>5ã€Elasticsearché…ç½®ï¼š</p>

<p>åœ¨ESé‡Œåˆ›å»ºgriffinç´¢å¼•ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl -XPUT http://es:9200/griffin -d '
{
    "aliases": {},
    "mappings": {
        "accuracy": {
            "properties": {
                "name": {
                    "fields": {
                        "keyword": {
                            "ignore_above": 256,
                            "type": "keyword"
                        }
                    },
                    "type": "text"
                },
                "tmst": {
                    "type": "date"
                }
            }
        }
    },
    "settings": {
        "index": {
            "number_of_replicas": "2",
            "number_of_shards": "5"
        }
    }
}
'
</code></pre></div></div>

<h4 id="æºç æ‰“åŒ…éƒ¨ç½²">æºç æ‰“åŒ…éƒ¨ç½²</h4>

<p>åœ¨è¿™é‡Œæˆ‘ä½¿ç”¨æºç ç¼–è¯‘æ‰“åŒ…çš„æ–¹å¼æ¥éƒ¨ç½²Griffinï¼ŒGriffinçš„æºç åœ°å€æ˜¯ï¼š<a href="https://github.com/apache/griffin.git">https://github.com/apache/griffin.git</a>ï¼Œè¿™é‡Œæˆ‘ä½¿ç”¨çš„æºç tagæ˜¯griffin-0.4.0ï¼Œä¸‹è½½å®Œæˆåœ¨ideaä¸­å¯¼å…¥å¹¶å±•å¼€æºç çš„ç»“æ„å›¾å¦‚ä¸‹ï¼š</p>

<p><img src="/images/project.jpg" alt="project" /></p>

<p>Griffinçš„æºç ç»“æ„å¾ˆæ¸…æ™°ï¼Œä¸»è¦åŒ…æ‹¬griffin-docã€measureã€serviceå’Œuiå››ä¸ªæ¨¡å—ï¼Œå…¶ä¸­griffin-docè´Ÿè´£å­˜æ”¾Griffinçš„æ–‡æ¡£ï¼Œmeasureè´Ÿè´£ä¸sparkäº¤äº’ï¼Œæ‰§è¡Œç»Ÿè®¡ä»»åŠ¡ï¼Œserviceä½¿ç”¨spring bootä½œä¸ºæœåŠ¡å®ç°ï¼Œè´Ÿè´£ç»™uiæ¨¡å—æä¾›äº¤äº’æ‰€éœ€çš„restful apiï¼Œä¿å­˜ç»Ÿè®¡ä»»åŠ¡ï¼Œå±•ç¤ºç»Ÿè®¡ç»“æœã€‚</p>

<p>æºç å¯¼å…¥æ„å»ºå®Œæ¯•åï¼Œéœ€è¦ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼Œå…·ä½“ä¿®æ”¹çš„é…ç½®æ–‡ä»¶å¦‚ä¸‹ï¼š</p>

<p>1ã€service/src/main/resources/application.propertiesï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Apache Griffinåº”ç”¨åç§°
spring.application.name=griffin_service
# MySQLæ•°æ®åº“é…ç½®ä¿¡æ¯
spring.datasource.url=jdbc:mysql://10.xxx.xx.xxx:3306/griffin_quartz?useSSL=false
spring.datasource.username=xxxxx
spring.datasource.password=xxxxx
spring.jpa.generate-ddl=true
spring.datasource.driver-class-name=com.mysql.jdbc.Driver
spring.jpa.show-sql=true
# Hive metastoreé…ç½®ä¿¡æ¯
hive.metastore.uris=thrift://namenode.test01.xxx:9083
hive.metastore.dbname=default
hive.hmshandler.retry.attempts=15
hive.hmshandler.retry.interval=2000ms
# Hive cache time
cache.evict.hive.fixedRate.in.milliseconds=900000
# Kafka schema registryï¼ŒæŒ‰éœ€é…ç½®
kafka.schema.registry.url=http://namenode.test01.xxx:8081
# Update job instance state at regular intervals
jobInstance.fixedDelay.in.milliseconds=60000
# Expired time of job instance which is 7 days that is 604800000 milliseconds.Time unit only supports milliseconds
jobInstance.expired.milliseconds=604800000
# schedule predicate job every 5 minutes and repeat 12 times at most
#interval time unit s:second m:minute h:hour d:day,only support these four units
predicate.job.interval=5m
predicate.job.repeat.count=12
# external properties directory location
external.config.location=
# external BATCH or STREAMING env
external.env.location=
# login strategy ("default" or "ldap")
login.strategy=default
# ldapï¼Œç™»å½•ç­–ç•¥ä¸ºldapæ—¶é…ç½®
ldap.url=ldap://hostname:port
ldap.email=@example.com
ldap.searchBase=DC=org,DC=example
ldap.searchPattern=(sAMAccountName={0})
# hdfs default name
fs.defaultFS=
# elasticsearché…ç½®
elasticsearch.host=griffindq02-test1-rgtj1-tj1
elasticsearch.port=9200
elasticsearch.scheme=http
# elasticsearch.user = user
# elasticsearch.password = password
# livyé…ç½®
livy.uri=http://10.104.xxx.xxx:8998/batches
# yarn urlé…ç½®
yarn.uri=http://10.104.xxx.xxx:8088
# griffin event listener
internal.event.listeners=GriffinJobEventHook
</code></pre></div></div>

<p>2ã€service/src/main/resources/quartz.properties</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#
# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
# 
#   http://www.apache.org/licenses/LICENSE-2.0
# 
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
org.quartz.scheduler.instanceName=spring-boot-quartz
org.quartz.scheduler.instanceId=AUTO
org.quartz.threadPool.threadCount=5
org.quartz.jobStore.class=org.quartz.impl.jdbcjobstore.JobStoreTX
# If you use postgresql as your database,set this property value to org.quartz.impl.jdbcjobstore.PostgreSQLDelegate
# If you use mysql as your database,set this property value to org.quartz.impl.jdbcjobstore.StdJDBCDelegate
# If you use h2 as your database, it's ok to set this property value to StdJDBCDelegate, PostgreSQLDelegate or others
org.quartz.jobStore.driverDelegateClass=org.quartz.impl.jdbcjobstore.StdJDBCDelegate
org.quartz.jobStore.useProperties=true
org.quartz.jobStore.misfireThreshold=60000
org.quartz.jobStore.tablePrefix=QRTZ_
org.quartz.jobStore.isClustered=true
org.quartz.jobStore.clusterCheckinInterval=20000
</code></pre></div></div>

<p>3ã€service/src/main/resources/sparkProperties.jsonï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  "file": "hdfs:///griffin/griffin-measure.jar",
  "className": "org.apache.griffin.measure.Application",
  "name": "griffin",
  "queue": "default",
  "numExecutors": 2,
  "executorCores": 1,
  "driverMemory": "1g",
  "executorMemory": "1g",
  "conf": {
    "spark.yarn.dist.files": "hdfs:///home/spark_conf/hive-site.xml"
  },
  "files": [
  ]
}
</code></pre></div></div>

<p>4ã€service/src/main/resources/env/env_batch.jsonï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  "spark": {
    "log.level": "INFO"
  },
  "sinks": [
    {
      "type": "CONSOLE",
      "config": {
        "max.log.lines": 10
      }
    },
    {
      "type": "HDFS",
      "config": {
        "path": "hdfs://namenodetest01.xx.xxxx.com:9001/griffin/persist",
        "max.persist.lines": 10000,
        "max.lines.per.file": 10000
      }
    },
    {
      "type": "ELASTICSEARCH",
      "config": {
        "method": "post",
        "api": "http://10.xxx.xxx.xxx:9200/griffin/accuracy",
        "connection.timeout": "1m",
        "retry": 10
      }
    }
  ],
  "griffin.checkpoint": []
}
</code></pre></div></div>

<p>é…ç½®æ–‡ä»¶ä¿®æ”¹å¥½åï¼Œåœ¨ideaé‡Œçš„terminalé‡Œæ‰§è¡Œå¦‚ä¸‹mavenå‘½ä»¤è¿›è¡Œç¼–è¯‘æ‰“åŒ…ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mvn -Dmaven.test.skip=true clean install
</code></pre></div></div>

<p>å‘½ä»¤æ‰§è¡Œå®Œæˆåï¼Œä¼šåœ¨serviceå’Œmeasureæ¨¡å—çš„targetç›®å½•ä¸‹åˆ†åˆ«çœ‹åˆ°service-0.4.0.jarå’Œmeasure-0.4.0.jarä¸¤ä¸ªjarï¼Œå°†è¿™ä¸¤ä¸ªjaråˆ†åˆ«æ‹·è´åˆ°æœåŠ¡å™¨ç›®å½•ä¸‹ã€‚è¿™ä¸¤ä¸ªjarçš„ä½¿ç”¨æ–¹å¼å¦‚ä¸‹ï¼š</p>

<p>1ã€ä½¿ç”¨å¦‚ä¸‹å‘½ä»¤å°†measure-0.4.0.jarè¿™ä¸ªjarä¸Šä¼ åˆ°HDFSçš„/griffinæ–‡ä»¶ç›®å½•é‡Œï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#æ”¹å˜jaråç§°
mv measure-0.4.0.jar griffin-measure.jar
#ä¸Šä¼ griffin-measure.jaråˆ°HDFSæ–‡ä»¶ç›®å½•é‡Œ
hadoop fs -put measure-0.4.0.jar /griffin/
</code></pre></div></div>

<p>è¿™æ ·åšçš„ç›®çš„ä¸»è¦æ˜¯å› ä¸ºsparkåœ¨yarné›†ç¾¤ä¸Šæ‰§è¡Œä»»åŠ¡æ—¶ï¼Œéœ€è¦åˆ°HDFSçš„/griffinç›®å½•ä¸‹åŠ è½½griffin-measure.jarï¼Œé¿å…å‘ç”Ÿç±»org.apache.griffin.measure.Applicationæ‰¾ä¸åˆ°çš„é”™è¯¯ã€‚</p>

<p>2ã€è¿è¡Œservice-0.4.0.jarï¼Œå¯åŠ¨Griffinç®¡ç†åå°ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nohup java -jar service-0.4.0.jar&gt;service.out 2&gt;&amp;1 &amp;
</code></pre></div></div>

<p>å‡ ç§’é’Ÿåï¼Œæˆ‘ä»¬å¯ä»¥è®¿é—®Apache Griffinçš„é»˜è®¤UI(é»˜è®¤æƒ…å†µä¸‹ï¼Œspring bootçš„ç«¯å£æ˜¯8080)ã€‚</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>http://IP:8080
</code></pre></div></div>

<p>UIæ“ä½œæ–‡æ¡£é“¾æ¥ï¼š<a href="https://github.com/apache/griffin/blob/master/griffin-doc/ui/user-guide.md">Apache Griffin User Guide</a>ã€‚é€šè¿‡UIæ“ä½œç•Œé¢ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºè‡ªå·±çš„ç»Ÿè®¡ä»»åŠ¡ï¼Œéƒ¨åˆ†ç»“æœå±•ç¤ºç•Œé¢å¦‚ä¸‹ï¼š</p>

<p><img src="/images/dashboard-big.png" alt="dashboard" /></p>

<h4 id="åŠŸèƒ½ä½“éªŒ">åŠŸèƒ½ä½“éªŒ</h4>

<p>1ã€åœ¨hiveé‡Œåˆ›å»ºè¡¨demo_srcå’Œdemo_tgtï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>--create hive tables here. hql script
--Note: replace hdfs location with your own path
CREATE EXTERNAL TABLE `demo_src`(
  `id` bigint,
  `age` int,
  `desc` string) 
PARTITIONED BY (
  `dt` string,
  `hour` string)
ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '|'
LOCATION
  'hdfs:///griffin/data/batch/demo_src';

--Note: replace hdfs location with your own path
CREATE EXTERNAL TABLE `demo_tgt`(
  `id` bigint,
  `age` int,
  `desc` string) 
PARTITIONED BY (
  `dt` string,
  `hour` string)
ROW FORMAT DELIMITED
  FIELDS TERMINATED BY '|'
LOCATION
  'hdfs:///griffin/data/batch/demo_tgt';
</code></pre></div></div>

<p>2ã€ç”Ÿæˆæµ‹è¯•æ•°æ®ï¼š</p>

<p>ä»<a href="http://griffin.apache.org/data/batch/">http://griffin.apache.org/data/batch/</a>åœ°å€ä¸‹è½½æ‰€æœ‰æ–‡ä»¶åˆ°HadoopæœåŠ¡å™¨ä¸Šï¼Œç„¶åä½¿ç”¨å¦‚ä¸‹å‘½ä»¤æ‰§è¡Œgen-hive-data.shè„šæœ¬ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>nohup ./gen-hive-data.sh&gt;gen.out 2&gt;&amp;1 &amp;
</code></pre></div></div>

<p>æ³¨æ„è§‚å¯Ÿgen.outæ—¥å¿—æ–‡ä»¶ï¼Œå¦‚æœæœ‰é”™è¯¯ï¼Œè§†æƒ…å†µè¿›è¡Œè°ƒæ•´ã€‚è¿™é‡Œæˆ‘çš„æµ‹è¯•ç¯å¢ƒHadoopå’ŒHiveå®‰è£…åœ¨åŒä¸€å°æœåŠ¡å™¨ä¸Šï¼Œå› æ­¤ç›´æ¥è¿è¡Œè„šæœ¬ã€‚</p>

<p>3ã€é€šè¿‡UIç•Œé¢åˆ›å»ºç»Ÿè®¡ä»»åŠ¡ï¼Œå…·ä½“æŒ‰ç…§<a href="https://github.com/apache/griffin/blob/master/griffin-doc/ui/user-guide.md">Apache Griffin User Guide</a>
ä¸€æ­¥æ­¥æ“ä½œã€‚</p>

<h3 id="è¸©å‘è¿‡ç¨‹">è¸©å‘è¿‡ç¨‹</h3>

<p>1ã€gen-hive-data.shè„šæœ¬ç”Ÿæˆæ•°æ®å¤±è´¥ï¼ŒæŠ¥no such file or directoryé”™è¯¯ã€‚</p>

<p>é”™è¯¯åŸå› ï¼šHDFSä¸­çš„/griffin/data/batch/demo_src/å’Œ/griffin/data/batch/demo_tgt/ç›®å½•ä¸‹â€dt=æ—¶é—´â€ç›®å½•ä¸å­˜åœ¨ï¼Œå¦‚dt=20190113ã€‚</p>

<p>è§£å†³åŠæ³•ï¼šç»™è„šæœ¬ä¸­å¢åŠ hadoop fs -mkdiråˆ›å»ºç›®å½•æ“ä½œï¼Œä¿®æ”¹å®Œåå¦‚ä¸‹ï¼š</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#!/bin/bash

#create table
hive -f create-table.hql
echo "create table done"

#current hour
sudo ./gen_demo_data.sh
cur_date=`date +%Y%m%d%H`
dt=${cur_date:0:8}
hour=${cur_date:8:2}
partition_date="dt='$dt',hour='$hour'"
sed s/PARTITION_DATE/$partition_date/ ./insert-data.hql.template &gt; insert-data.hql
hive -f insert-data.hql
src_done_path=/griffin/data/batch/demo_src/dt=${dt}/hour=${hour}/_DONE
tgt_done_path=/griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}/_DONE
hadoop fs -mkdir -p /griffin/data/batch/demo_src/dt=${dt}/hour=${hour}
hadoop fs -mkdir -p /griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}
hadoop fs -touchz ${src_done_path}
hadoop fs -touchz ${tgt_done_path}
echo "insert data [$partition_date] done"

#last hour
sudo ./gen_demo_data.sh
cur_date=`date -d '1 hour ago' +%Y%m%d%H`
dt=${cur_date:0:8}
hour=${cur_date:8:2}
partition_date="dt='$dt',hour='$hour'"
sed s/PARTITION_DATE/$partition_date/ ./insert-data.hql.template &gt; insert-data.hql
hive -f insert-data.hql
src_done_path=/griffin/data/batch/demo_src/dt=${dt}/hour=${hour}/_DONE
tgt_done_path=/griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}/_DONE
hadoop fs -mkdir -p /griffin/data/batch/demo_src/dt=${dt}/hour=${hour}
hadoop fs -mkdir -p /griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}
hadoop fs -touchz ${src_done_path}
hadoop fs -touchz ${tgt_done_path}
echo "insert data [$partition_date] done"

#next hours
set +e
while true
do
  sudo ./gen_demo_data.sh
  cur_date=`date +%Y%m%d%H`
  next_date=`date -d "+1hour" '+%Y%m%d%H'`
  dt=${next_date:0:8}
  hour=${next_date:8:2}
  partition_date="dt='$dt',hour='$hour'"
  sed s/PARTITION_DATE/$partition_date/ ./insert-data.hql.template &gt; insert-data.hql
  hive -f insert-data.hql
  src_done_path=/griffin/data/batch/demo_src/dt=${dt}/hour=${hour}/_DONE
  tgt_done_path=/griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}/_DONE
  hadoop fs -mkdir -p /griffin/data/batch/demo_src/dt=${dt}/hour=${hour}
  hadoop fs -mkdir -p /griffin/data/batch/demo_tgt/dt=${dt}/hour=${hour}
  hadoop fs -touchz ${src_done_path}
  hadoop fs -touchz ${tgt_done_path}
  echo "insert data [$partition_date] done"
  sleep 3600
done
set -e
</code></pre></div></div>

<p>2ã€HDFSçš„/griffin/persistç›®å½•ä¸‹æ²¡æœ‰ç»Ÿè®¡ç»“æœæ–‡ä»¶ï¼Œæ£€æŸ¥è¯¥ç›®å½•çš„æƒé™ï¼Œè®¾ç½®åˆé€‚çš„æƒé™å³å¯ã€‚</p>

<p>3ã€ESä¸­çš„metricæ•°æ®ä¸ºç©ºï¼Œæœ‰ä¸¤ç§å¯èƒ½ï¼š</p>

<ul>
  <li>service/src/main/resources/env/env_batch.jsoné‡Œçš„ESé…ç½®ä¿¡æ¯ä¸æ­£ç¡®</li>
  <li>æ‰§è¡Œsparkä»»åŠ¡çš„yarnæœåŠ¡å™¨ä¸Šæ²¡æœ‰é…ç½®ESæœåŠ¡å™¨çš„hostnameï¼Œè¿æ¥å¼‚å¸¸</li>
</ul>

<p>4ã€å¯åŠ¨service-0.4.0.jarä¹‹åï¼Œè®¿é—®ä¸åˆ°UIç•Œé¢ï¼ŒæŸ¥çœ‹å¯åŠ¨æ—¥å¿—æ— å¼‚å¸¸ã€‚æ£€æŸ¥æ‰“åŒ…æ—¶æ˜¯ä¸æ˜¯æ‰§è¡Œçš„mvn packageå‘½ä»¤ï¼Œå°†è¯¥å‘½ä»¤æ›¿æ¢æˆmvn -Dmaven.test.skip=true clean installå‘½ä»¤é‡æ–°æ‰“åŒ…å¯åŠ¨å³å¯ã€‚</p>

:ET